# -*- coding: utf-8 -*-
"""Untitled75.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tlz7DCgsLouUQ0OTHZ-KFDDMj-IooORk
"""

# --- Import necessary libraries ---
import kagglehub
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
)

from imblearn.over_sampling import SMOTE

warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output

# --- Download dataset ---
dataset_path = kagglehub.dataset_download("akshaydattatraykhare/diabetes-dataset")
print(f"Dataset downloaded to: {dataset_path}")

# --- Download dataset ---
dataset_path = kagglehub.dataset_download("akshaydattatraykhare/diabetes-dataset")
print(f"Dataset downloaded to: {dataset_path}")

# --- Load data ---
data = pd.read_csv("diabetes.csv")

# ===========================================
# Data Overview
# ===========================================

print("\n--- Dataset Preview (first 5 rows) ---")
print(data.head())

print(f"\n--- Dataset Shape: {data.shape} (rows, columns) ---")

print("\n--- Dataset Information ---")
data.info()

print("\n--- Missing Values per Column ---")
print(data.isnull().sum())

# ===========================================
# Exploratory Data Analysis (EDA)
# ===========================================

# Set plotting style for all visuals
sns.set_style("whitegrid")

# Distribution histograms for numerical features
fig, axes = plt.subplots(3, 3, figsize=(20, 15))
axes = axes.flatten()
for i, col in enumerate(data.columns):
    if data[col].dtype != 'object':
        sns.histplot(data[col], kde=True, ax=axes[i], color='steelblue')
        axes[i].set_title(f'Distribution of {col}', fontsize=14)
        axes[i].set_xlabel(col, fontsize=12)
        axes[i].set_ylabel('Frequency', fontsize=12)
plt.tight_layout()
plt.show()

print("Histograms for all numerical features have been displayed.\n")

# Boxplots: Features vs Outcome
numerical_features = data.select_dtypes(include=['int64', 'float64']).columns.drop('Outcome')
num_features = len(numerical_features)
num_cols = 3
num_rows = (num_features + num_cols - 1) // num_cols

fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 6, num_rows * 5))
axes = axes.flatten()

for i, feature in enumerate(numerical_features):
    sns.boxplot(x='Outcome', y=feature, data=data, ax=axes[i], palette='viridis', hue='Outcome', dodge=False, legend=False)
    axes[i].set_title(f'{feature} Distribution by Outcome', fontsize=14)
    axes[i].set_xlabel('Outcome (0 = No Diabetes, 1 = Diabetes)', fontsize=12)
    axes[i].set_ylabel(feature, fontsize=12)

# Remove empty subplots
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

print("Box plots displaying feature distributions by Outcome have been shown.\n")

# Correlation heatmap
corr_matrix = data.corr()
plt.figure(figsize=(7, 5))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=2)
plt.title('Correlation Matrix of Features', fontsize=16)
plt.show()

print("Correlation heatmap completed.\n")

# ===========================================
# Data Preprocessing
# ===========================================

# Separate features and target variable
X = data.drop('Outcome', axis=1)
y = data['Outcome']

print(f"Feature matrix X shape: {X.shape}")
print(f"Target vector y shape: {y.shape}\n")

# Split dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

print(f"Training set shapes: X_train = {X_train.shape}, y_train = {y_train.shape}")
print(f"Test set shapes: X_test = {X_test.shape}, y_test = {y_test.shape}\n")

# Scale features using StandardScaler (fit on training data only)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Feature scaling completed using StandardScaler.\n")

# ===========================================
# Address Class Imbalance with SMOTE
# ===========================================

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("Original training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nAfter applying SMOTE, training set class distribution:")
print(pd.Series(y_train_resampled).value_counts())

print(f"\nTraining set size before SMOTE: {X_train.shape[0]} samples")
print(f"Training set size after SMOTE: {X_train_resampled.shape[0]} samples\n")

# ===========================================
# Model Training and Evaluation Function
# ===========================================

def evaluate_model(model, X_test, y_test, model_name="Model"):
    """
    Trains the model, makes predictions, and prints evaluation metrics
    including accuracy, precision, recall, F1-score, classification report,
    and displays a confusion matrix heatmap.
    """
    model.fit(X_train_resampled, y_train_resampled)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

    print(f"--- {model_name} Performance Metrics ---")
    print(f"Accuracy : {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall   : {rec:.4f}")
    print(f"F1-Score : {f1:.4f}\n")

    print(f"Classification Report for {model_name}:\n")
    print(classification_report(y_test, y_pred, zero_division=0))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f'{model_name} Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.xticks(ticks=[0.5,1.5], labels=['No Diabetes (0)', 'Diabetes (1)'])
    plt.yticks(ticks=[0.5,1.5], labels=['No Diabetes (0)', 'Diabetes (1)'], rotation=0)
    plt.show()

    return {'model': model_name, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1_score': f1}

# ===========================================
# Train and Evaluate Models
# ===========================================

# Logistic Regression
log_reg = LogisticRegression(random_state=42, solver='liblinear')
log_reg_results = evaluate_model(log_reg, X_test, y_test, "Logistic Regression")

# Support Vector Classifier
svc = SVC(random_state=42, probability=True)
svc_results = evaluate_model(svc, X_test, y_test, "Support Vector Machine")

# Gradient Boosting Classifier
gbc = GradientBoostingClassifier(random_state=42)
gbc_results = evaluate_model(gbc, X_test, y_test, "Gradient Boosting Classifier")

# ===========================================
# Summary and Best Model Identification
# ===========================================

results = [log_reg_results, svc_results, gbc_results]

print("\n--- Summary of Model Performances ---")
for res in results:
    print(f"{res['model']}: Accuracy={res['accuracy']*100:.2f}, Precision={res['precision']*100:.2f}, "
          f"Recall={res['recall']*100:.2f}, F1-Score={res['f1_score']*100:.2f}")

# Determine best model based on F1-score
best_model = max(results, key=lambda x: x['f1_score'])
print(f"\nBest performing model: {best_model['model']} with F1-Score = {best_model['f1_score']*100:.2f}")

# Optionally, save the best model for later use
import joblib
model_filename = f"best_model_{best_model['model'].lower().replace(' ', '_')}.joblib"
joblib.dump(best_model['model'], model_filename)
print(f"Best model saved as: {model_filename}")